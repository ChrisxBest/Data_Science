{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c28c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#connect to Spark\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .appName(\"ML mit SparkML\")\n",
    "         .getOrCreate()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757a25f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('aggregated_HDD_Data.csv', header=True, inferSchema=True)\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ae8213",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "brand_indexer = StringIndexer(inputCol=\"brand\", outputCol=\"brand_indexed\")  # initialize indexer\n",
    "brand_indexer = brand_indexer.fit(df)  # fit indexer to dataframe\n",
    "df = brand_indexer.transform(df)  # encode brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b145da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_indexer = StringIndexer(inputCol=\"model\", outputCol=\"model_indexed\")\n",
    "model_indexer = model_indexer.fit(df)\n",
    "df = model_indexer.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa93117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['model', 'model_indexed']].show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a913fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"brand\", \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8f4ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encode model and brand column\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "#initialize\n",
    "encoder = OneHotEncoder(inputCols=['model_indexed', 'brand_indexed'],\n",
    "                        outputCols=['model_onehot', 'brand_onehot'])\n",
    "\n",
    "#fit and apply\n",
    "encoder = encoder.fit(df)\n",
    "df = encoder.transform(df)\n",
    "\n",
    "#drop old columns\n",
    "df = df.drop('model_indexed', 'brand_indexed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676d0742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename target col to label -> spark default for target\n",
    "df = df.withColumnRenamed(\"failure\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68fafea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all columns that we want to use as features\n",
    "feature_cols = [col for col in df.columns if col not in ['serial_number', 'days_live', 'label']]\n",
    "\n",
    "# import and initialize VectorAssembler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_cols,\n",
    "                            outputCol=\"features\")\n",
    "\n",
    "# Now let us use the transform method to transform our dataset\n",
    "df = assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4b7a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = df.randomSplit(weights=[0.9, 0.1],\n",
    "                                   seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb564df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# register training set table for use in SQL queries.\n",
    "df_train.createOrReplaceTempView(\"train_set\")\n",
    "\n",
    "spark.sql(\"\"\"SELECT label, COUNT(label)\n",
    "FROM train_set        \n",
    "GROUP BY label\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59ab864",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_classes = spark.sql(\"\"\"SELECT label, COUNT(label)\n",
    "                                FROM train_set\n",
    "                                GROUP BY label\"\"\").toPandas()\n",
    "df_train_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688b0afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_count = df_train.count()\n",
    "df_train_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2bb9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_classes.index = df_train_classes.loc[:, 'label']\n",
    "weights = df_train_count / df_train_classes.loc[:, 'count(label)']\n",
    "\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b967caa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "df_train = df_train.withColumn(\"weights\",\n",
    "                               when(df_train[\"label\"] == 0, weights.loc[0]).otherwise(weights.loc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c7fdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(weightCol=\"weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b28825",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.fit(df_train)\n",
    "df_test_pred = model.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e58e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_pred.select('prediction').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd819d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_summary = model.evaluate(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6afe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy:', pred_summary.accuracy)\n",
    "print('recall:', pred_summary.recallByLabel)\n",
    "print('AUC:', pred_summary.areaUnderROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f745021b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
