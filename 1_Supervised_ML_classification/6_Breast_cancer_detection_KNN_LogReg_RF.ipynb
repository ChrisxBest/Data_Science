{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b10f0ff",
   "metadata": {},
   "source": [
    "**1. Vorbereitung der Daten für die statistische Modellierung**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b453fcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data sets, convert datatypes and data imputation\n",
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv('breastcancer_train.csv')\n",
    "df_test = pd.read_csv('breastcancer_test.csv')\n",
    "df_aim = pd.read_csv('breastcancer_aim.csv')\n",
    "\n",
    "display(df_train.head())\n",
    "display(df_test.head())\n",
    "display(df_aim.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1b9b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_train.describe().T)\n",
    "display(df_test.describe().T)\n",
    "display(df_aim.describe().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb1eb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print shapes\n",
    "print(\"Train\", df_train.shape)\n",
    "print(\"Test\", df_test.shape)\n",
    "print(\"Aim\", df_aim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5de03d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking datatypes\n",
    "df_train.info()\n",
    "print(\"\\n\")\n",
    "df_test.info()\n",
    "print(\"\\n\")\n",
    "df_aim.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a6a337",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count missing values\n",
    "print(df_train.isna().sum())\n",
    "print(df_test.isna().sum())\n",
    "print(df_aim.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7065f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#handling missing values \n",
    "df_train = df_train.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd69f6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check train set\n",
    "print(\"Train\", df_train.shape)\n",
    "print(df_train.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734a02de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing datatypes\n",
    "df_train.loc[:, 'id'] = df_train.loc[:, 'id'].astype('category')\n",
    "df_train.loc[:, 'bare_nucleoli'] = df_train.loc[:, 'bare_nucleoli'].astype('int')\n",
    "df_train.loc[:, 'class'] = df_train.loc[:, 'class'].astype('category')\n",
    "\n",
    "df_test.loc[:, 'id'] = df_test.loc[:, 'id'].astype('category')\n",
    "df_test.loc[:, 'bare_nucleoli'] = df_test.loc[:, 'bare_nucleoli'].astype('int')\n",
    "df_test.loc[:, 'class'] = df_test.loc[:, 'class'].astype('category')\n",
    "\n",
    "df_aim.loc[:, 'id'] = df_aim.loc[:, 'id'].astype('category')\n",
    "df_aim.loc[:, 'bare_nucleoli'] = df_aim.loc[:, 'bare_nucleoli'].astype('int')\n",
    "df_aim.loc[:, 'class'] = df_aim.loc[:, 'class'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9f76b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking datatypes again\n",
    "df_train.info()\n",
    "print(\"\\n\")\n",
    "df_test.info()\n",
    "print(\"\\n\")\n",
    "df_aim.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a77763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature matrices and target vectors\n",
    "features_train = df_train.drop(['class', 'id'], axis=1)\n",
    "features_test = df_test.drop(['class', 'id'], axis=1)\n",
    "features_aim = df_aim.drop(['class', 'id'], axis=1)\n",
    "\n",
    "target_train = df_train.loc[:,'class']\n",
    "target_test = df_test.loc[:,'class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d4e1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Zuerst die Korrelationsmatrix berechnen\n",
    "correlation_matrix = features_train.corr()\n",
    "\n",
    "# 1. Erstellen einer Maske für das obere Dreieck\n",
    "# np.triu(matrix) gibt das obere Dreieck der Matrix zurück, wobei alles unterhalb\n",
    "# der Hauptdiagonalen auf 0 gesetzt wird.\n",
    "# Wir wollen aber das UNTERE Dreieck maskieren. Die Standardmaske für seaborn.heatmap\n",
    "# ist True für die zu maskierenden Bereiche.\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "\n",
    "# Plot-Größe festlegen\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Heatmap erstellen\n",
    "sns.heatmap(\n",
    "    correlation_matrix,\n",
    "    mask=mask,       # Wenden Sie die Maske an, um den unteren Teil auszublenden\n",
    "    annot=True,      # Koeffizienten anzeigen\n",
    "    fmt='.2f',       # Format auf zwei Dezimalstellen\n",
    "    vmin=-1,         # Farbskala-Minimum\n",
    "    vmax=1,          # Farbskala-Maximum\n",
    "    cmap='coolwarm'  # Eine Farbskala, die positiv/negativ gut unterscheidet\n",
    ")\n",
    "\n",
    "# Titel und Anzeige\n",
    "plt.title('Korrelationsmatrix (Oberes Dreieck)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b14f55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class distribution among train- and test set\n",
    "target_prop_train = pd.crosstab(index=target_train, columns='count')\n",
    "display(target_prop_train)\n",
    "target_prop_test = pd.crosstab(index=target_test, columns='count')\n",
    "display(target_prop_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3318ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform highly correlated data\n",
    "col_correlated = ['clump_thickness', \n",
    "                  'size_uniformity',\n",
    "                  'shape_uniformity',\n",
    "                  'marginal_adhesion',\n",
    "                  'epithelial_size',\n",
    "                  'bare_nucleoli',\n",
    "                  'normal_nucleoli'\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63e1ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d71628",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_pca = Pipeline([('std', StandardScaler()), \n",
    "                    ('pca', PCA(n_components=0.8))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa5b487",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_corr_train = std_pca.fit_transform(features_train.loc[:, col_correlated])\n",
    "features_train = features_train.drop(col_correlated, axis=1)\n",
    "features_train.loc[:, 'pca_0'] = arr_corr_train[:, 0]\n",
    "features_train.loc[:, 'pca_1'] = arr_corr_train[:, 1]\n",
    "features_train.loc[:, 'pca_2'] = arr_corr_train[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0527f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_corr_test = std_pca.transform(features_test.loc[:, col_correlated])\n",
    "features_test = features_test.drop(col_correlated, axis=1)\n",
    "features_test.loc[:, 'pca_0'] = arr_corr_test[:, 0]\n",
    "features_test.loc[:, 'pca_1'] = arr_corr_test[:, 1]\n",
    "features_test.loc[:, 'pca_2'] = arr_corr_test[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b2c723",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(features_train.loc[:, :].corr().tail(3))\n",
    "display(features_test.loc[:, :].corr().tail(3))\n",
    "display(features_train.describe().T.tail(3))\n",
    "display(features_test.describe().T.tail(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad7aa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features_train.shape)\n",
    "features_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b62fb6",
   "metadata": {},
   "source": [
    "**2. Ermittlung der Performance der statistischen Klassifikationsmodelle auf den Trainingsdaten**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ffc0d6",
   "metadata": {},
   "source": [
    "**KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf86b7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best k-nearfrom sklearn.neighbors import KNeighborsClassifierest neighbors model on train set \n",
    "# nicht korrelierte Features müssen ebenfalls standardisiert werden -> nochmals alles standardisieren!\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "pipeline_knn = Pipeline([('std', StandardScaler()),\n",
    "                         ('knn', KNeighborsClassifier())])\n",
    "\n",
    "k = np.unique(np.geomspace(1, 20, 20, dtype='int'))  # create 20 values between 1 and 20 with increasing distance\n",
    "\n",
    "search_space_knn = {'knn__n_neighbors': k,  # use the created values as number of neighbors\n",
    "                    'knn__weights': ['uniform', 'distance']}\n",
    "search_space_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10244a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model_knn = GridSearchCV(estimator=pipeline_knn, \n",
    "                         param_grid=search_space_knn, \n",
    "                         scoring='f1',\n",
    "                         cv=5)\n",
    "\n",
    "model_knn.fit(features_train, target_train)\n",
    "\n",
    "print(model_knn.best_estimator_)\n",
    "print(model_knn.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb75afec",
   "metadata": {},
   "source": [
    "**Log Reg**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d1fa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best logistic regression model on train set \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipeline_log = Pipeline([('std', StandardScaler()),\n",
    "                         ('log', LogisticRegression(solver='saga',\n",
    "                                                    class_weight='balanced',\n",
    "                                                    max_iter=1e4,\n",
    "                                                    random_state=42))])\n",
    "\n",
    "C_values = np.geomspace(start=0.001, stop=1000, num=14)\n",
    "\n",
    "search_space_log = {'log__penalty': ['l1', 'l2'],\n",
    "                    'log__C': C_values\n",
    "                   }\n",
    "search_space_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da203cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log = GridSearchCV(estimator=pipeline_log,\n",
    "                         param_grid=search_space_log,\n",
    "                         scoring='f1',\n",
    "                         cv=5)\n",
    "\n",
    "model_log.fit(features_train, target_train)\n",
    "\n",
    "print(model_log.best_estimator_)\n",
    "print(model_log.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f970ad",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aa7872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best random forst model on train set \n",
    "# RF muss nicht standardisiert werden!\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "search_space_rf = {'max_depth': np.geomspace(start=3, stop=50, num=10, dtype='int'),\n",
    "                   'min_samples_leaf': np.geomspace(start=1, stop=500, num=10, dtype='int')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c97b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = GridSearchCV(estimator=RandomForestClassifier(class_weight='balanced',\n",
    "                                                         n_estimators=50,\n",
    "                                                         random_state=42),\n",
    "                        param_grid=search_space_rf,\n",
    "                        scoring='f1',\n",
    "                        cv=5)\n",
    "\n",
    "model_rf.fit(features_train, target_train)\n",
    "\n",
    "print(model_rf.best_estimator_)\n",
    "print(model_rf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1ba9c3",
   "metadata": {},
   "source": [
    "**3. Evaluation der statistischen Klassifikationsmodelle auf den Testdaten**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfe8d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate classifiers on test set\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "for clf in [model_knn, model_log, model_rf]:\n",
    "    \n",
    "    target_test_pred = clf.predict(features_test)\n",
    "    \n",
    "    print('\\nPrecision: ', precision_score(target_test, target_test_pred))\n",
    "    print('Recall: ', recall_score(target_test, target_test_pred))\n",
    "    print('F1: ', f1_score(target_test, target_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c49537",
   "metadata": {},
   "source": [
    "**4. Vorhersage des Zielvektors auf den Zieldaten mithilfe des besten statistischen Klassifikationsmodells**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3cb36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions on aim set\n",
    "arr_corr_aim = std_pca.transform(features_aim.loc[:, col_correlated])\n",
    "features_aim = features_aim.drop(col_correlated, axis=1)\n",
    "features_aim.loc[:, 'pca_0'] = arr_corr_aim[:, 0]\n",
    "features_aim.loc[:, 'pca_1'] = arr_corr_aim[:, 1]\n",
    "features_aim.loc[:, 'pca_2'] = arr_corr_aim[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934c2059",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aim.loc[: , 'Prediction'] = model_rf.predict(features_aim)\n",
    "sum(df_aim.loc[: , 'Prediction'])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
