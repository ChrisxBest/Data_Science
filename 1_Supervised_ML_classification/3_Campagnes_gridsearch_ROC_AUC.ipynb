{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7a97a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module import\n",
    "import pandas as pd\n",
    "import pdpipe as pdp\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "df_train = pd.read_csv('marketing_train.csv')\n",
    "df_test = pd.read_csv('marketing_test.csv')\n",
    "df_aim = pd.read_csv('marketing_aim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13d76ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lösung:\n",
    "print(df_train.info())\n",
    "print(df_test.info())\n",
    "print(df_aim.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf20f78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.describe())\n",
    "print(df_test.describe())\n",
    "print(df_aim.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a02a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deal with -1 values in 'Days passed'\n",
    "\n",
    "# Lösung:\n",
    "import numpy as np\n",
    "\n",
    "def cleaner(df):\n",
    "    for row in range(df.shape[0]):\n",
    "        if df.loc[row, 'Days passed'] == -1:\n",
    "            df.loc[row, 'Days passed'] = np.nan\n",
    "            \n",
    "cleaner(df=df_train)\n",
    "cleaner(df=df_test)\n",
    "cleaner(df=df_aim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d853c336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class distribution in train set and test set\n",
    "\n",
    "# Lösung:\n",
    "print(pd.crosstab(df_train.loc[:, 'Subscribed deposit'], columns='count', normalize=True))\n",
    "print(pd.crosstab(df_test.loc[:, 'Subscribed deposit'], columns='count', normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c40503",
   "metadata": {},
   "source": [
    "**2. Vorbereitung der Daten für die statistische Modellierung**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb01918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deal with NaN values\n",
    "\n",
    "# Lösung:\n",
    "df_train = df_train.dropna(axis=0)\n",
    "df_test = df_test.dropna(axis=0)\n",
    "df_aim = df_aim.dropna(axis=0)\n",
    "\n",
    "print(df_train.isna().sum())\n",
    "print(df_test.isna().sum())\n",
    "print(df_aim.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57077bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation matrix\n",
    "\n",
    "# Lösung:\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots(nrows=3, figsize=(20, 20))\n",
    "\n",
    "mask_train = np.triu(np.ones_like(df_train.corr(), dtype=bool))\n",
    "sns.heatmap(df_train.corr(), mask=mask_train, vmin=-1, vmax=1, fmt='.2f', annot=True, ax=ax[0]);\n",
    "\n",
    "mask_test = np.triu(np.ones_like(df_test.corr(), dtype=bool))\n",
    "sns.heatmap(df_test.corr(), mask=mask_test, vmin=-1, vmax=1, fmt='.2f',annot=True, ax=ax[1]);\n",
    "\n",
    "mask_aim = np.triu(np.ones_like(df_aim.corr(), dtype=bool))\n",
    "sns.heatmap(df_aim.corr(), mask=mask_aim, vmin=-1, vmax=1, fmt='.2f',annot=True, ax=ax[2]);\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8151aa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of unique values for categorial columns\n",
    "\n",
    "# Lösung:\n",
    "cat_cols = ['Job',\n",
    "            'Marital Status',\n",
    "            'Education',\n",
    "            'Has credit in default',\n",
    "            'Has housing loan',\n",
    "            'Has personal loan',\n",
    "            'Contact type',\n",
    "            'Last contact month',\n",
    "            'Outcome previous campaign',\n",
    "            'Subscribed deposit']\n",
    "\n",
    "for cat_col in cat_cols:\n",
    "    print(cat_col,': ', \n",
    "          df_train.loc[:, cat_col].nunique(), \n",
    "          df_train.loc[:, cat_col].unique())\n",
    "\n",
    "print('\\n\\n')\n",
    "for cat_col in cat_cols:\n",
    "    print(cat_col,': ', \n",
    "          df_test.loc[:, cat_col].nunique(), \n",
    "          df_test.loc[:, cat_col].unique())\n",
    "\n",
    "print('\\n\\n')\n",
    "for cat_col in cat_cols[:-1]:\n",
    "    print(cat_col,': ', \n",
    "          df_aim.loc[:, cat_col].nunique(),\n",
    "          df_aim.loc[:, cat_col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b467da3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding\n",
    "\n",
    "# Lösung:\n",
    "bin_cols = ['Has credit in default',\n",
    "            'Has housing loan',\n",
    "            'Has personal loan',\n",
    "            'Subscribed deposit']\n",
    "\n",
    "dict_label_encoding = {'no': 0, 'yes': 1}\n",
    "\n",
    "for bin_col in bin_cols:\n",
    "    df_train = df_train.replace(to_replace={bin_col: dict_label_encoding})\n",
    "    df_test = df_test.replace(to_replace={bin_col: dict_label_encoding})\n",
    "    \n",
    "for bin_col in bin_cols[:-1]:\n",
    "    df_aim = df_aim.replace(to_replace={bin_col: dict_label_encoding})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72677b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding\n",
    "\n",
    "# Lösung:\n",
    "import pdpipe as pdp\n",
    "\n",
    "onehot = pdp.OneHotEncode(['Job', \n",
    "                           'Marital Status', \n",
    "                           'Education', \n",
    "                           'Contact type',\n",
    "                           'Last contact month',\n",
    "                           'Outcome previous campaign'], drop_first=False)\n",
    "\n",
    "df_train = onehot.fit_transform(df_train) # always fit on train set only!\n",
    "df_test = onehot.transform(df_test)\n",
    "df_aim = onehot.transform(df_aim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19b51e7",
   "metadata": {},
   "source": [
    "**3. Modellierung der Daten anhand einer logistischen Regression und Identifizierung der besten Hyperparametereinstellungen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffac7e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic model\n",
    "\n",
    "# Lösung:\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipeline_log = Pipeline([('scaler', StandardScaler()),\n",
    "                         ('classifier', LogisticRegression(solver='saga',\n",
    "                                                           max_iter=10000, \n",
    "                                                           random_state=42))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c885abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gridsearch with cross-validation\n",
    "\n",
    "# Lösung:\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "features_train = df_train.iloc[:, :-1]\n",
    "target_train = df_train.iloc[:, -1]\n",
    "\n",
    "search_space_grid = [{'classifier__penalty': ['l1', 'l2'],\n",
    "                      'classifier__C': np.geomspace(start=0.001, stop=1000, num=14)}]\n",
    "\n",
    "model_grid = GridSearchCV(estimator=pipeline_log,\n",
    "                          param_grid=search_space_grid,\n",
    "                          scoring='roc_auc',\n",
    "                          cv=5,\n",
    "                          n_jobs=-1)\n",
    "\n",
    "model_grid.fit(features_train, target_train)\n",
    "\n",
    "print(model_grid.best_estimator_)\n",
    "print(model_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d04ea3",
   "metadata": {},
   "source": [
    "**4. Evaluierung des gefundenen besten logistischen Regressionsmodells** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2da5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate best model on test set\n",
    "\n",
    "# Lösung:\n",
    "features_test = df_test.iloc[:, :-1]\n",
    "target_test = df_test.iloc[:, -1]\n",
    "\n",
    "target_test_pred_proba = model_grid.best_estimator_.predict_proba(features_test)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(target_test, target_test_pred_proba[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a649808",
   "metadata": {},
   "source": [
    "**5. Vorhersage der Festgeldkonten-Zuordnung** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04ac767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction on aim set\n",
    "\n",
    "# Lösung:\n",
    "features_aim = df_aim.copy()\n",
    "df_aim.loc[:, 'subdep_pred_proba'] = model_grid.predict_proba(features_aim)[:, 1]\n",
    "df_aim.loc[:, 'subdep_pred'] = model_grid.predict(features_aim)\n",
    "\n",
    "pd.crosstab(df_aim.loc[:, 'subdep_pred'], columns='count')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
